# ğŸ§ª FormulAI â€“ AI-Powered Cosmetic Formulation Assistant

FormulAI is an AI-driven tool that helps cosmetic scientists and product developers generate effective, safe cosmetic product formulas. It uses a Retrieval-Augmented Generation (RAG) pipeline with FAISS for vector search, Hugging Face for embeddings, and Ollama for local large language model generation.

---

## âœ¨ Features

- ğŸ§  **Retrieval-Augmented Generation** using past formulas as context
- ğŸ” Filtered retrieval by product type and skin type
- ğŸ¤– Local LLM generation via Ollama (e.g. LLaMA 3)
- ğŸ“¦ CSV export of structured formulas
- ğŸ§ª Ingredient and phase-aware output format
- ğŸ–¥ Built with Streamlit for interactive UI

---

## ğŸ“‚ Project Structure

formulai/
â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ rag_formulai.py # RAG pipeline logic
â”œâ”€â”€ generate_chunks.py # Parses CSV + creates enriched chunks
â”œâ”€â”€ formulations_filled_parts.csv # Raw input data
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ venv/ # Local virtual environment
â””â”€â”€ faiss_index/
â”œâ”€â”€ formulai.index # FAISS vector index
â”œâ”€â”€ formulai_enriched_chunks.json # Chunked data + metadata


---

## ğŸš€ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/your-username/FormulAI.git
cd FormulAI

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

python generate_chunks.py

streamlit run app.py

Make sure Ollama is running and that youâ€™ve pulled a model like:

ollama pull llama3

ğŸ›  Tech Stack
LLM: Ollama (LLaMA 3, Mistral, etc.)

Embedding: Sentence-Transformers (all-MiniLM-L6-v2)

Vector Store: FAISS (local)

UI: Streamlit

Data: CSV of real cosmetic formulations

ğŸ“„ License
MIT License. See LICENSE for details.
